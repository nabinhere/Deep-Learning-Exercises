{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMeGF9QGtQoTaDTX8OFqx91"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"EOqGGpjFcglx","executionInfo":{"status":"ok","timestamp":1720424115824,"user_tz":-345,"elapsed":16737,"user":{"displayName":"Nabindra Shrestha","userId":"01740359431384572488"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms"]},{"cell_type":"code","source":["# device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"y67kBCDHkcV3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Hyperparameters\n","input_size = 28\n","sequence_length = 28\n","num_layers = 2\n","hidden_size= 128\n","num_classes = 10\n","num_epochs = 2\n","batch_size = 100\n","learning_rate = 0.001"],"metadata":{"id":"kZ7OiWN2knwQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# datasets\n","train_dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, transform=transforms.ToTensor(), download=True)\n","test_dataset = torchvision.datasets.MNIST(root=\"./data\", train=False, transform=transforms.ToTensor(), download=True)\n","\n","# Data loader\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"],"metadata":{"id":"IPoq8mGMlpDU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model class\n","class RNN(nn.Module):\n","  def __init__(self, input_size, hidden_size, num_layers, num_classes):\n","    super(RNN, self).__init__()\n","    self.num_layers = num_layers\n","    self.hidden_size = hidden_size\n","    self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n","    self.fc = nn.Linear(hidden_size, num_classes)\n","\n","  def forward(self, x):\n","    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n","    out, _ = self.rnn(x, h0)\n","    out=  out[:, -1, :]\n","    out=  self.fc(out)\n","    return out\n","\n"],"metadata":{"id":"qdtdBZk0mdpK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model= RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n","\n","# Loss and optimizer\n","crieterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n"],"metadata":{"id":"HK3cvq973j2X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","n_total_steps = len(train_loader)\n","for epoch in range(num_epochs):\n","  for i, (images, labels) in enumerate(train_loader):\n","    images = images.reshape(-1, sequence_length, input_size).to(device)\n","    labels = labels.to(device)\n","\n","    # forward pass\n","    outputs = model(images)\n","    loss = crieterion(outputs, labels)\n","\n","    # backward and optimize\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (i+1)%10==0:\n","      print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"soG7DkW84L2v","executionInfo":{"status":"ok","timestamp":1720160529005,"user_tz":-345,"elapsed":65529,"user":{"displayName":"Nabindra Shrestha","userId":"01740359431384572488"}},"outputId":"6d40167a-777d-4730-d013-08b82bb85cc9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/2], Step [10/600], Loss: 2.1492\n","Epoch [1/2], Step [20/600], Loss: 1.7614\n","Epoch [1/2], Step [30/600], Loss: 1.4831\n","Epoch [1/2], Step [40/600], Loss: 1.3096\n","Epoch [1/2], Step [50/600], Loss: 1.2199\n","Epoch [1/2], Step [60/600], Loss: 1.1492\n","Epoch [1/2], Step [70/600], Loss: 0.9703\n","Epoch [1/2], Step [80/600], Loss: 1.1338\n","Epoch [1/2], Step [90/600], Loss: 0.7897\n","Epoch [1/2], Step [100/600], Loss: 0.8115\n","Epoch [1/2], Step [110/600], Loss: 0.7216\n","Epoch [1/2], Step [120/600], Loss: 0.9243\n","Epoch [1/2], Step [130/600], Loss: 0.6988\n","Epoch [1/2], Step [140/600], Loss: 0.9381\n","Epoch [1/2], Step [150/600], Loss: 0.8351\n","Epoch [1/2], Step [160/600], Loss: 0.6626\n","Epoch [1/2], Step [170/600], Loss: 0.7633\n","Epoch [1/2], Step [180/600], Loss: 0.7625\n","Epoch [1/2], Step [190/600], Loss: 0.5900\n","Epoch [1/2], Step [200/600], Loss: 0.8431\n","Epoch [1/2], Step [210/600], Loss: 0.5948\n","Epoch [1/2], Step [220/600], Loss: 0.7990\n","Epoch [1/2], Step [230/600], Loss: 0.8173\n","Epoch [1/2], Step [240/600], Loss: 0.6408\n","Epoch [1/2], Step [250/600], Loss: 0.4995\n","Epoch [1/2], Step [260/600], Loss: 0.6750\n","Epoch [1/2], Step [270/600], Loss: 0.6989\n","Epoch [1/2], Step [280/600], Loss: 0.6124\n","Epoch [1/2], Step [290/600], Loss: 0.5420\n","Epoch [1/2], Step [300/600], Loss: 0.5748\n","Epoch [1/2], Step [310/600], Loss: 0.4693\n","Epoch [1/2], Step [320/600], Loss: 0.4022\n","Epoch [1/2], Step [330/600], Loss: 0.6744\n","Epoch [1/2], Step [340/600], Loss: 0.4927\n","Epoch [1/2], Step [350/600], Loss: 0.3492\n","Epoch [1/2], Step [360/600], Loss: 0.5024\n","Epoch [1/2], Step [370/600], Loss: 0.4431\n","Epoch [1/2], Step [380/600], Loss: 0.6678\n","Epoch [1/2], Step [390/600], Loss: 0.5675\n","Epoch [1/2], Step [400/600], Loss: 0.3848\n","Epoch [1/2], Step [410/600], Loss: 0.4449\n","Epoch [1/2], Step [420/600], Loss: 0.2933\n","Epoch [1/2], Step [430/600], Loss: 0.3181\n","Epoch [1/2], Step [440/600], Loss: 0.3384\n","Epoch [1/2], Step [450/600], Loss: 0.3426\n","Epoch [1/2], Step [460/600], Loss: 0.3074\n","Epoch [1/2], Step [470/600], Loss: 0.3850\n","Epoch [1/2], Step [480/600], Loss: 0.2592\n","Epoch [1/2], Step [490/600], Loss: 0.4195\n","Epoch [1/2], Step [500/600], Loss: 0.2635\n","Epoch [1/2], Step [510/600], Loss: 0.4713\n","Epoch [1/2], Step [520/600], Loss: 0.4209\n","Epoch [1/2], Step [530/600], Loss: 0.2810\n","Epoch [1/2], Step [540/600], Loss: 0.1825\n","Epoch [1/2], Step [550/600], Loss: 0.2525\n","Epoch [1/2], Step [560/600], Loss: 0.4522\n","Epoch [1/2], Step [570/600], Loss: 0.1761\n","Epoch [1/2], Step [580/600], Loss: 0.3117\n","Epoch [1/2], Step [590/600], Loss: 0.3467\n","Epoch [1/2], Step [600/600], Loss: 0.3253\n","Epoch [2/2], Step [10/600], Loss: 0.3020\n","Epoch [2/2], Step [20/600], Loss: 0.3385\n","Epoch [2/2], Step [30/600], Loss: 0.1910\n","Epoch [2/2], Step [40/600], Loss: 0.2877\n","Epoch [2/2], Step [50/600], Loss: 0.2731\n","Epoch [2/2], Step [60/600], Loss: 0.3918\n","Epoch [2/2], Step [70/600], Loss: 0.2339\n","Epoch [2/2], Step [80/600], Loss: 0.2514\n","Epoch [2/2], Step [90/600], Loss: 0.2086\n","Epoch [2/2], Step [100/600], Loss: 0.2374\n","Epoch [2/2], Step [110/600], Loss: 0.2549\n","Epoch [2/2], Step [120/600], Loss: 0.1756\n","Epoch [2/2], Step [130/600], Loss: 0.2715\n","Epoch [2/2], Step [140/600], Loss: 0.1688\n","Epoch [2/2], Step [150/600], Loss: 0.3273\n","Epoch [2/2], Step [160/600], Loss: 0.3516\n","Epoch [2/2], Step [170/600], Loss: 0.4795\n","Epoch [2/2], Step [180/600], Loss: 0.1492\n","Epoch [2/2], Step [190/600], Loss: 0.1631\n","Epoch [2/2], Step [200/600], Loss: 0.2268\n","Epoch [2/2], Step [210/600], Loss: 0.3808\n","Epoch [2/2], Step [220/600], Loss: 0.1995\n","Epoch [2/2], Step [230/600], Loss: 0.2291\n","Epoch [2/2], Step [240/600], Loss: 0.3656\n","Epoch [2/2], Step [250/600], Loss: 0.1688\n","Epoch [2/2], Step [260/600], Loss: 0.2882\n","Epoch [2/2], Step [270/600], Loss: 0.1858\n","Epoch [2/2], Step [280/600], Loss: 0.2810\n","Epoch [2/2], Step [290/600], Loss: 0.3474\n","Epoch [2/2], Step [300/600], Loss: 0.1957\n","Epoch [2/2], Step [310/600], Loss: 0.1711\n","Epoch [2/2], Step [320/600], Loss: 0.2261\n","Epoch [2/2], Step [330/600], Loss: 0.2141\n","Epoch [2/2], Step [340/600], Loss: 0.2149\n","Epoch [2/2], Step [350/600], Loss: 0.1991\n","Epoch [2/2], Step [360/600], Loss: 0.2032\n","Epoch [2/2], Step [370/600], Loss: 0.2830\n","Epoch [2/2], Step [380/600], Loss: 0.1569\n","Epoch [2/2], Step [390/600], Loss: 0.2265\n","Epoch [2/2], Step [400/600], Loss: 0.1806\n","Epoch [2/2], Step [410/600], Loss: 0.2030\n","Epoch [2/2], Step [420/600], Loss: 0.2723\n","Epoch [2/2], Step [430/600], Loss: 0.1957\n","Epoch [2/2], Step [440/600], Loss: 0.2066\n","Epoch [2/2], Step [450/600], Loss: 0.1530\n","Epoch [2/2], Step [460/600], Loss: 0.2148\n","Epoch [2/2], Step [470/600], Loss: 0.3069\n","Epoch [2/2], Step [480/600], Loss: 0.2252\n","Epoch [2/2], Step [490/600], Loss: 0.0997\n","Epoch [2/2], Step [500/600], Loss: 0.1622\n","Epoch [2/2], Step [510/600], Loss: 0.2955\n","Epoch [2/2], Step [520/600], Loss: 0.1166\n","Epoch [2/2], Step [530/600], Loss: 0.1493\n","Epoch [2/2], Step [540/600], Loss: 0.1813\n","Epoch [2/2], Step [550/600], Loss: 0.2364\n","Epoch [2/2], Step [560/600], Loss: 0.1357\n","Epoch [2/2], Step [570/600], Loss: 0.2696\n","Epoch [2/2], Step [580/600], Loss: 0.1381\n","Epoch [2/2], Step [590/600], Loss: 0.0702\n","Epoch [2/2], Step [600/600], Loss: 0.1800\n"]}]},{"cell_type":"code","source":["# Test the model\n","with torch.no_grad():\n","  n_correct=0\n","  n_samples=0\n","  for images, labels in test_loader:\n","    images = images.reshape(-1, sequence_length, input_size).to(device)\n","    labels = labels.to(device)\n","    outputs = model(images)\n","    # max returns(value, index)\n","    _, predicted = torch.max(outputs.data, 1)\n","    n_samples += labels.size(0)\n","    n_correct += (predicted==labels).sum().item()\n","\n","acc = 100.0*n_correct/n_samples\n","print(f'Accuracy of the model on the 10000 test images: {acc} %')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IXvJUHrU5bbS","executionInfo":{"status":"ok","timestamp":1720160532258,"user_tz":-345,"elapsed":3256,"user":{"displayName":"Nabindra Shrestha","userId":"01740359431384572488"}},"outputId":"048d3832-9015-4bfe-e3e5-74edcc55129e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the model on the 10000 test images: 94.25 %\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"6XdrsJVP6lOl"},"execution_count":null,"outputs":[]}]}